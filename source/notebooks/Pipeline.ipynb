{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Desktop\\BA\\notebooks\\testing\\preprocessing.py:100: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[dateid] = df[dateid].map(lambda x: pd.Timestamp(x))\n"
     ]
    }
   ],
   "source": [
    "from preprocessing import Preprocessor\n",
    "\n",
    "path_to_config = \"../../data/train.ini\"\n",
    "path_to_data = \"../../data/train.csv\"\n",
    "\n",
    "prep = Preprocessor()\n",
    "prep.process(path_to_config=path_to_config, path_to_data=path_to_data, csv_delimiter=',')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting counts. This may take some time.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:00<00:00, 210.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating initial state probabilities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating state transition probabilities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating observation probabilities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 5999.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction of probabilities successful. Elapsed time: 0.0 hours, 0.0 minutes and 0.0469970703125 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pvault import ProbabilityVault\n",
    "\n",
    "pv = ProbabilityVault(prep)\n",
    "pv.extract_probabilities()\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "{'id': {0: 0.125,\n  1: 0.125,\n  2: 0.125,\n  3: 0.125,\n  4: 0.125,\n  5: 0.125,\n  6: 0.125,\n  7: 0.125},\n 'date': {0: 0.5, 44: 0.125, 52: 0.375},\n 'siteid': {0: 0.625, 2: 0.375},\n 'walk': {1: 0.75, 2: 0.25},\n 'handedness': {1: 1.0},\n 'diagnosis': {1: 0.75, 2: 0.25}}"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cp = pv.get_cparser()\n",
    "pv.get_isp_dict()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from model import DynamicNaiveBayesClassifier\n",
    "\n",
    "dnbc = DynamicNaiveBayesClassifier(pv)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e3534fd-6486-4d6b-bad0-5773207c4f8f",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\Desktop\\BA\\notebooks\\testing\\pvault.py:401: UserWarning: layer motoric was to be consulted for prediction, but was not found                  in the valid markers. Please check for spelling.\n",
      "  warnings.warn(f\"layer {layer} was to be consulted for prediction, but was not found \\\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "y contains previously unseen labels: '2021-02-01'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\utils\\_encode.py:224\u001B[0m, in \u001B[0;36m_encode\u001B[1;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 224\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_map_to_integer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvalues\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    225\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001B[0m, in \u001B[0;36m_map_to_integer\u001B[1;34m(values, uniques)\u001B[0m\n\u001B[0;32m    163\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[1;32m--> 164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([table[v] \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\utils\\_encode.py:164\u001B[0m, in \u001B[0;36m<listcomp>\u001B[1;34m(.0)\u001B[0m\n\u001B[0;32m    163\u001B[0m table \u001B[38;5;241m=\u001B[39m _nandict({val: i \u001B[38;5;28;01mfor\u001B[39;00m i, val \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(uniques)})\n\u001B[1;32m--> 164\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([\u001B[43mtable\u001B[49m\u001B[43m[\u001B[49m\u001B[43mv\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m v \u001B[38;5;129;01min\u001B[39;00m values])\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\utils\\_encode.py:158\u001B[0m, in \u001B[0;36m_nandict.__missing__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    157\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnan_value\n\u001B[1;32m--> 158\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: '2021-02-01'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[1;32mIn [6]\u001B[0m, in \u001B[0;36m<cell line: 5>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m path_to_observation \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m../../data/obs.csv\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m      3\u001B[0m obs_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mread_csv(path_to_observation, delimiter\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m,\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 5\u001B[0m post_distr \u001B[38;5;241m=\u001B[39m \u001B[43mdnbc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mposterior_distribution\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mid\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlayers\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mmotoric\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mvisit_specific\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobservation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mobs_df\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\BA\\notebooks\\testing\\model.py:67\u001B[0m, in \u001B[0;36mDynamicNaiveBayesClassifier.posterior_distribution\u001B[1;34m(self, hidden_marker, layers, observation)\u001B[0m\n\u001B[0;32m     63\u001B[0m distributions \u001B[38;5;241m=\u001B[39m {}\n\u001B[0;32m     65\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m observation_marker \u001B[38;5;129;01min\u001B[39;00m unique_markers:\n\u001B[1;32m---> 67\u001B[0m     distributions[observation_marker] \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_probs\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhidden_marker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobservation_marker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobservation\u001B[49m\u001B[43m[\u001B[49m\u001B[43mobservation_marker\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     69\u001B[0m warnings\u001B[38;5;241m.\u001B[39mwarn(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mEXPERIMENTAL CODE: layer weights are not applied, since the code for layer-weights is still missing. \u001B[39m\u001B[38;5;130;01m\\\u001B[39;00m\n\u001B[0;32m     70\u001B[0m \u001B[38;5;124mThe distr of weights over the layers is an equal distribution for now.\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     73\u001B[0m \u001B[38;5;66;03m# 3) apply weights to the distributions, sum up the distributions\u001B[39;00m\n",
      "File \u001B[1;32m~\\Desktop\\BA\\notebooks\\testing\\model.py:90\u001B[0m, in \u001B[0;36mDynamicNaiveBayesClassifier.forward_probs\u001B[1;34m(self, hidden_marker, observation_marker, observation_sequence)\u001B[0m\n\u001B[0;32m     87\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_probs\u001B[39m(\u001B[38;5;28mself\u001B[39m, hidden_marker, observation_marker, observation_sequence : pd\u001B[38;5;241m.\u001B[39mSeries):\n\u001B[0;32m     88\u001B[0m     \n\u001B[0;32m     89\u001B[0m     \u001B[38;5;66;03m# 1) encode series of values\u001B[39;00m\n\u001B[1;32m---> 90\u001B[0m     obs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_pv\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mobservation_marker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mobservation_sequence\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     92\u001B[0m     num_hidden_states \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pv\u001B[38;5;241m.\u001B[39mnum_states_for_marker(hidden_marker)\n\u001B[0;32m     93\u001B[0m     timesteps \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlen\u001B[39m(obs)\n",
      "File \u001B[1;32m~\\Desktop\\BA\\notebooks\\testing\\pvault.py:459\u001B[0m, in \u001B[0;36mProbabilityVault.encode\u001B[1;34m(self, marker, series)\u001B[0m\n\u001B[0;32m    457\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mencode\u001B[39m(\u001B[38;5;28mself\u001B[39m, marker, series):\n\u001B[1;32m--> 459\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_prep\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencode_series\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmarker\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mseries\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\Desktop\\BA\\notebooks\\testing\\preprocessing.py:243\u001B[0m, in \u001B[0;36mPreprocessor.encode_series\u001B[1;34m(self, marker, series)\u001B[0m\n\u001B[0;32m    240\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    241\u001B[0m     result \u001B[38;5;241m=\u001B[39m series\n\u001B[1;32m--> 243\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_label_encoders\u001B[49m\u001B[43m[\u001B[49m\u001B[43mmarker\u001B[49m\u001B[43m]\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mresult\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:138\u001B[0m, in \u001B[0;36mLabelEncoder.transform\u001B[1;34m(self, y)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m _num_samples(y) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[0;32m    136\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m np\u001B[38;5;241m.\u001B[39marray([])\n\u001B[1;32m--> 138\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_encode\u001B[49m\u001B[43m(\u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43muniques\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mclasses_\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\sklearn\\utils\\_encode.py:226\u001B[0m, in \u001B[0;36m_encode\u001B[1;34m(values, uniques, check_unknown)\u001B[0m\n\u001B[0;32m    224\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m _map_to_integer(values, uniques)\n\u001B[0;32m    225\u001B[0m     \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m--> 226\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124my contains previously unseen labels: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mstr\u001B[39m(e)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    227\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    228\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m check_unknown:\n",
      "\u001B[1;31mValueError\u001B[0m: y contains previously unseen labels: '2021-02-01'"
     ]
    }
   ],
   "source": [
    "path_to_observation = \"../../data/obs.csv\"\n",
    "\n",
    "obs_df = pd.read_csv(path_to_observation, delimiter=',')\n",
    "\n",
    "post_distr = dnbc.posterior_distribution('id', layers=['motoric', 'visit_specific'], observation=obs_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "N = post_distr.shape[1]\n",
    "M = post_distr.shape[0]\n",
    "series = pd.Series(range(M))\n",
    "\n",
    "series = prep.decode_series('id', series)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.stackplot(range(N), post_distr, labels=series)\n",
    "plt.legend()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "pv.get_isp_dict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcc481c-70d4-45a4-a339-1c149b3549ab",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}