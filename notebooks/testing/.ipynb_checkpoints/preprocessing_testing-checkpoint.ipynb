{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b67c293c",
   "metadata": {},
   "source": [
    "# Preprocessing data for generic HMM generation\n",
    "    \n",
    "In the following notebook, our aim will be to layout the idea of preprocessing the initial data, in order to\n",
    "enable a **stable Machine-Learning performance** later on!\n",
    "\n",
    "The workflow is shown in the figure below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181a8910",
   "metadata": {},
   "source": [
    "![PreprocessingPipelineImage](images/PreprocessingPipeline.png \"View of the Preprocessing Pipeline\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f3fe02",
   "metadata": {},
   "source": [
    "We start by receiving the data in the csv format, together with a .ini file conforming to the abtract syntax defined in\n",
    "markerconfig.esl.\n",
    "\n",
    "First, we delete all unnecessary data, which means 'ignoring' certain columns which are specified in the config file.\n",
    "Then, we group the data by person (or to be more generic, by every experiement run). Thus, we obtain timeseries for each run.\n",
    "These timeseries might not be consistent in frequency, which is why we have to install this consistency within the data.\n",
    "This means inserting empty Datapoints inbetween the data, or dropping some of the data (This part is to be discussed in detail).\n",
    "Finally, we generate a label encoder for our data, transform our data per Marker and thus make the data easier and faster to work with.\n",
    "\n",
    "Subsequently, we obtain a csv file with time consistent sequences as well as a map from Marker to LabelEncoder objects used to transform the encoded values back to their original names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf7b0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import configparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bbbadef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_config = \"config.ini\"\n",
    "path_to_data = \"..\\..\\data\\csv_klinischeDaten\\Konstante_u_fortlaufende_Daten_identifier-nur-ID\\test.csv\"\n",
    "\n",
    "# read in the config file\n",
    "cparser = configparser.ConfigParser()\n",
    "cparser.read(path_to_config)\n",
    "\n",
    "# read in the data and store it into a dataframe\n",
    "df = pd.read_csv(path_to_data, delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e754f2cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['markerconfig_metainfo',\n",
       " 'usubjid',\n",
       " 'visdat',\n",
       " 'siteid',\n",
       " 'scacat',\n",
       " 'mutationspc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cparser.sections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1be9dd0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usubjid</th>\n",
       "      <th>siteid</th>\n",
       "      <th>subjstat</th>\n",
       "      <th>visnam</th>\n",
       "      <th>visdat</th>\n",
       "      <th>visstat</th>\n",
       "      <th>seq</th>\n",
       "      <th>scacat</th>\n",
       "      <th>scacat2</th>\n",
       "      <th>carrier</th>\n",
       "      <th>...</th>\n",
       "      <th>short</th>\n",
       "      <th>long</th>\n",
       "      <th>mutationspc</th>\n",
       "      <th>tested</th>\n",
       "      <th>scancat</th>\n",
       "      <th>ataxia</th>\n",
       "      <th>aoo2</th>\n",
       "      <th>scacontrol</th>\n",
       "      <th>oldstudy</th>\n",
       "      <th>oldid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385-408-939</td>\n",
       "      <td>13</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>editing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>C.62G&gt;A</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>047-817-379</td>\n",
       "      <td>13</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>editing</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>FXTAS im FMR1-Gen / 75 repeats</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>13</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>editing</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2014</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>13</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>editing</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>13</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>editing</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>241-461-921</td>\n",
       "      <td>4</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>plausible</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>72</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>1</td>\n",
       "      <td>SCA-BON-0181-0002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>063-320-056</td>\n",
       "      <td>7</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>completed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>14</td>\n",
       "      <td>70</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>418-918-735</td>\n",
       "      <td>6</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>completed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>29</td>\n",
       "      <td>62</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>734-755-048</td>\n",
       "      <td>7</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>completed</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>739-031-141</td>\n",
       "      <td>7</td>\n",
       "      <td>enroled</td>\n",
       "      <td>Logs</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>completed</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>.</td>\n",
       "      <td>67</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         usubjid  siteid subjstat visnam      visdat    visstat  seq scacat  \\\n",
       "0    385-408-939      13  enroled   Logs  2021-09-02    editing    1      1   \n",
       "1    047-817-379      13  enroled   Logs  2021-08-31    editing    1      1   \n",
       "2    237-034-721      13  enroled   Logs  2021-08-31    editing    1      2   \n",
       "3    237-034-721      13  enroled   Logs  2021-08-31    editing    1      .   \n",
       "4    237-034-721      13  enroled   Logs  2021-08-31    editing    1      .   \n",
       "..           ...     ...      ...    ...         ...        ...  ...    ...   \n",
       "916  241-461-921       4  enroled   Logs  2017-05-10  plausible    1      1   \n",
       "917  063-320-056       7  enroled   Logs  2017-05-08  completed    1      1   \n",
       "918  418-918-735       6  enroled   Logs  2017-05-02  completed    1      1   \n",
       "919  734-755-048       7  enroled   Logs  2017-04-30  completed    1      3   \n",
       "920  739-031-141       7  enroled   Logs  2017-04-30  completed    1      1   \n",
       "\n",
       "    scacat2 carrier  ... short long                     mutationspc tested  \\\n",
       "0        14       1  ...     .    .                         C.62G>A      .   \n",
       "1         .       1  ...     .    .  FXTAS im FMR1-Gen / 75 repeats      .   \n",
       "2         .       .  ...     .    .                               .      .   \n",
       "3         .       .  ...     .    .                               .      .   \n",
       "4         .       .  ...     .    .                               .      .   \n",
       "..      ...     ...  ...   ...  ...                             ...    ...   \n",
       "916       3       1  ...    14   72                               .      .   \n",
       "917       3       1  ...    14   70                               .      .   \n",
       "918       3       1  ...    29   62                               .      .   \n",
       "919       .       .  ...     .    .                               .      .   \n",
       "920       3       1  ...     .   67                               .      .   \n",
       "\n",
       "    scancat ataxia  aoo2 scacontrol oldstudy              oldid  \n",
       "0         .      .     .          .        .                  .  \n",
       "1         .      .     .          .        .                  .  \n",
       "2         1      1  2014          .        .                  .  \n",
       "3         2      .     .          .        .                  .  \n",
       "4         3      .     .          .        .                  .  \n",
       "..      ...    ...   ...        ...      ...                ...  \n",
       "916       .      .     .          .        1  SCA-BON-0181-0002  \n",
       "917       .      .     .          .        .                  .  \n",
       "918       .      .     .          .        .                  .  \n",
       "919       .      .     .          2        .                  .  \n",
       "920       .      .     .          .        .                  .  \n",
       "\n",
       "[921 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdd83cf",
   "metadata": {},
   "source": [
    "## Delete unnecessary data\n",
    "\n",
    "- delete any unwanted columns\n",
    "- delete any excluded rows (?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d423974a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>usubjid</th>\n",
       "      <th>visdat</th>\n",
       "      <th>siteid</th>\n",
       "      <th>scacat</th>\n",
       "      <th>mutationspc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>385-408-939</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>C.62G&gt;A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>047-817-379</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>FXTAS im FMR1-Gen / 75 repeats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>237-034-721</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>13</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>241-461-921</td>\n",
       "      <td>2017-05-10</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>063-320-056</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>418-918-735</td>\n",
       "      <td>2017-05-02</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>734-755-048</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>739-031-141</td>\n",
       "      <td>2017-04-30</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>921 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         usubjid      visdat  siteid scacat                     mutationspc\n",
       "0    385-408-939  2021-09-02      13      1                         C.62G>A\n",
       "1    047-817-379  2021-08-31      13      1  FXTAS im FMR1-Gen / 75 repeats\n",
       "2    237-034-721  2021-08-31      13      2                               .\n",
       "3    237-034-721  2021-08-31      13      .                               .\n",
       "4    237-034-721  2021-08-31      13      .                               .\n",
       "..           ...         ...     ...    ...                             ...\n",
       "916  241-461-921  2017-05-10       4      1                               .\n",
       "917  063-320-056  2017-05-08       7      1                               .\n",
       "918  418-918-735  2017-05-02       6      1                               .\n",
       "919  734-755-048  2017-04-30       7      3                               .\n",
       "920  739-031-141  2017-04-30       7      1                               .\n",
       "\n",
       "[921 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop any columns/sections that are not specified in the config.ini file.\n",
    "valid_sections = cparser.sections()\n",
    "\n",
    "if 'markerconfig_metainfo' in valid_sections:\n",
    "    valid_sections.remove('markerconfig_metainfo')\n",
    "\n",
    "df = df[valid_sections]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a87465dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time1 = pd.Timestamp('2020-12-12')\n",
    "time2 = pd.Timestamp('2021-12-12')\n",
    "time3 = pd.Timestamp('2021-12-13')\n",
    "\n",
    "\n",
    "td1 = time2 - time1\n",
    "td2 = time3 - time2\n",
    "\n",
    "t = [1,2,3]\n",
    "t[1:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb0f341",
   "metadata": {},
   "source": [
    "## Group data by experiment\n",
    "\n",
    "Either we have a csv file in which more than one experiment is stored, or we have\n",
    "one big time-sequence. We need to query the 'markerconfig_metainfo' section of the configfile\n",
    "to find out, if we need to split the data into respective groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dda4096d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def group(df : pd.DataFrame, cparser : dict) -> [pd.DataFrame]:\n",
    "    '''\n",
    "    df :        The dataframe consisting of ungrouped, unsorted datapoints\n",
    "    cparser :   The configparser dictionary (maybe) containing metainfo about by what column\n",
    "                to group the data\n",
    "    returns :   A list of DataFrames grouped by the given attribute, if no attribute was supplied inside the\n",
    "                cparser, then the received DataFrame is returned without grouping, as a single element list.\n",
    "    '''\n",
    "    # check if we have metainfo, if we dont,\n",
    "    # we have to treat the data as one big experiment\n",
    "    if 'markerconfig_metainfo' not in cparser or 'groupby' not in cparser['markerconfig_metainfo']:\n",
    "        return [df]\n",
    "\n",
    "    # load our key, witch which we are grouping the data.\n",
    "    key = cparser['markerconfig_metainfo']['groupby']\n",
    "        \n",
    "    if key not in df.columns:\n",
    "        raise KeyError(f\"The groupby-key '{key}' specified inside the config file isn't found in the data.\")\n",
    "    \n",
    "    tmpdf = df.groupby(key)\n",
    "    return [tmpdf.get_group(group) for group in tmpdf.groups]\n",
    "    \n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8f1eea3",
   "metadata": {},
   "source": [
    "## Enforce measurement interval consistency (if wanted)\n",
    "\n",
    "In most cases, the time between measurements matters. In our case, state transitions are being observed with\n",
    "every experiment sequence. These transitions may not be observed within fixed time intervals. Severe inconsitencies in observation intervals between experiments may lead to a poor model performance. Thus, we query the metainfo about the time interval requested for the data and insert empty datapoints or delete duplicate datapoints in case we have to.\n",
    "\n",
    "\n",
    "\n",
    "<span style=\"color:red\">*This idea should be discussed, since this basically is a tradeoff between model accuracy and training data. Maybe we should just repeat the last state in the given time interval, until the new state is reached* </span>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a7aa117d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def enforce_timeinterval_consistency(dfs : [pd.DataFrame], cparser: dict) -> [pd.DataFrame]:\n",
    "    \n",
    "    if 'markerconfig_metainfo' not in cparser or 'dateinfo' not in cparser['markerconfig_metainfo']:\n",
    "        return dfs\n",
    "    \n",
    "    dateid, time1, time2 = eval(cparser['markerconfig_metainfo']['dateinfo'])\n",
    "    groupby = cparser['markerconfig_metainfo']['groupby'] if 'groupby' in cparser['markerconfig_metainfo'] else None\n",
    "    \n",
    "    \n",
    "    timedelta = pd.Timestamp(time1) - pd.Timestamp(time2)\n",
    "    \n",
    "    for i in range(len(dfs)):\n",
    "        dfs[i] = make_df_timeinterval_consistent(dfs[i], timedelta, dateid, groupby)\n",
    "        \n",
    "    \n",
    "    return dfs\n",
    "        \n",
    "def make_df_timeinterval_consistent(df : pd.DataFrame, timedelta : pd.Timedelta, dateid : str, groupby : str) -> pd.DataFrame:\n",
    "    '''\n",
    "    df :        The dataframe we want to enforce time interval consistency on\n",
    "    timedelta : Timedelta object, the maximum time delta, that two observations are allowed away from each other.\n",
    "    returns :   A time inteval consistent DataFrame. The new DataFrame may contain empty rows (filler rows are added\n",
    "                when two observations are too far away from each other), or fewer rows than before (when observations are\n",
    "                to close to each other, say all on the same day, we have to drop all but one).\n",
    "    '''\n",
    "    if dateid not in df.columns:\n",
    "        raise KeyError(f\"dateid-key {dateid}, which was specified inside the config.ini was not in the data.\")\n",
    "    \n",
    "    if groupby is not None:\n",
    "        group_handle = df[groupby].iloc[0]\n",
    "    \n",
    "    \n",
    "    # 1) remove duplicate values\n",
    "    df = df.drop_duplicates(subset=[dateid])\n",
    "    \n",
    "    \n",
    "    # 2) map the dates to pd.Timestamp objects\n",
    "    df[dateid] = df[dateid].map(lambda x: pd.Timestamp(x))\n",
    "    \n",
    "    # sort the dataframe by dates\n",
    "    df = df.sort_values(by=[dateid]).reset_index(drop=True)\n",
    "    \n",
    "    # 3) Allocate new rows inside a list. Fill in empty rows, in case we have a temporal gap\n",
    "    new_rows = []\n",
    "    dates = df[dateid]\n",
    "    \n",
    "    # always add the first date. In the following loop, we will add subsequent dates,\n",
    "    # aswell as filler rows.\n",
    "    new_rows.append(df.iloc[0].to_dict())\n",
    "    \n",
    "    for i in range(1, len(dates)):\n",
    "        current_date = dates.iloc[i-1]\n",
    "        next_date = dates.iloc[i]\n",
    "        \n",
    "        if timedelta < next_date - current_date:\n",
    "            \n",
    "            # add some filler rows\n",
    "            periods = 2 + int((next_date - current_date) / timedelta)\n",
    "            \n",
    "            times = pd.date_range(start=current_date, end=next_date, periods=periods)\n",
    "            \n",
    "            rows = [{dateid : x, groupby : group_handle} if groupby is not None else {dateid : x} for x in times[1:-1]]\n",
    "\n",
    "            new_rows = new_rows + rows\n",
    "            \n",
    "        # append next row to list\n",
    "        new_rows.append(df.iloc[i].to_dict())\n",
    "\n",
    "            \n",
    "    return pd.DataFrame(new_rows, columns=df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "097bfb7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\richard\\AppData\\Local\\Temp\\ipykernel_11504\\4014645792.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[dateid] = df[dateid].map(lambda x: pd.Timestamp(x))\n"
     ]
    }
   ],
   "source": [
    "grouped_dfs = group(df, cparser)\n",
    "consistant_dfs = enforce_timeinterval_consistency(grouped_dfs, cparser)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d72987",
   "metadata": {},
   "source": [
    "## Encoding states\n",
    "\n",
    "Since we have a list of DataFrames after the time interval enforcement, we have to concatenate all those single grouped Frames into a singular big DataFrame.\n",
    "\n",
    "To encode the states, we read in the information that every marker has attached to it, in some special cases, we actually need to perform some more operations, in order to make the dataset ready for usage.\n",
    "\n",
    "These special cases include for example the dtype linspace(x,y,bins), which is there to help us with continuous values.\n",
    "In this case, we have to extract the metainfo from the configfile, contruct a np.linspace object, then perform a transformation\n",
    "of the data via np.digitize. The same goes for the date_range dtype.\n",
    "\n",
    "In the end, we should be presented with multiple DataFrames, one per Layer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eaa26e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(consistant_dfs).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bed40ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dtype of section visdat was parsed as linspace(0, 10, 6), but we encountered an error.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'float' and 'Timestamp'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\numpy\\core\\fromnumeric.py:57\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'Timestamp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m     bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(start, end, number_bins)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# transform section of df with the help of bins!\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     df[section] \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43msection\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype of section \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was parsed as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but we encountered an error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\pandas\\core\\series.py:4237\u001b[0m, in \u001b[0;36mSeries.map\u001b[1;34m(self, arg, na_action)\u001b[0m\n\u001b[0;32m   4162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmap\u001b[39m(\u001b[38;5;28mself\u001b[39m, arg, na_action\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[0;32m   4163\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4164\u001b[0m \u001b[38;5;124;03m    Map values of Series according to an input mapping or function.\u001b[39;00m\n\u001b[0;32m   4165\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4235\u001b[0m \u001b[38;5;124;03m    dtype: object\u001b[39;00m\n\u001b[0;32m   4236\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4238\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor(new_values, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39m__finalize__(\n\u001b[0;32m   4239\u001b[0m         \u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmap\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   4240\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\pandas\\core\\base.py:880\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action)\u001b[0m\n\u001b[0;32m    877\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m    879\u001b[0m \u001b[38;5;66;03m# mapper is a function\u001b[39;00m\n\u001b[1;32m--> 880\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mmap_f\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    882\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m new_values\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\pandas\\_libs\\lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m     16\u001b[0m     bins \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(start, end, number_bins)\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;66;03m# transform section of df with the help of bins!\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m     df[section] \u001b[38;5;241m=\u001b[39m df[section]\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdigitize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbins\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     22\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype of section \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m was parsed as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, but we encountered an error.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\numpy\\lib\\function_base.py:5507\u001b[0m, in \u001b[0;36mdigitize\u001b[1;34m(x, bins, right)\u001b[0m\n\u001b[0;32m   5505\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(bins) \u001b[38;5;241m-\u001b[39m _nx\u001b[38;5;241m.\u001b[39msearchsorted(bins[::\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], x, side\u001b[38;5;241m=\u001b[39mside)\n\u001b[0;32m   5506\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 5507\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearchsorted\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbins\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\numpy\\core\\fromnumeric.py:1387\u001b[0m, in \u001b[0;36msearchsorted\u001b[1;34m(a, v, side, sorter)\u001b[0m\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_searchsorted_dispatcher)\n\u001b[0;32m   1320\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearchsorted\u001b[39m(a, v, side\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m, sorter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1321\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;124;03m    Find indices where elements should be inserted to maintain order.\u001b[39;00m\n\u001b[0;32m   1323\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1385\u001b[0m \n\u001b[0;32m   1386\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1387\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msearchsorted\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mside\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mside\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msorter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msorter\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\numpy\\core\\fromnumeric.py:66\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m bound(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\ba\\lib\\site-packages\\numpy\\core\\fromnumeric.py:43\u001b[0m, in \u001b[0;36m_wrapit\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m:\n\u001b[0;32m     42\u001b[0m     wrap \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wrap:\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, mu\u001b[38;5;241m.\u001b[39mndarray):\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'float' and 'Timestamp'"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#TODO: generate a LabelEncoder object for each marker, encode each column!\n",
    "label_encoders = {}\n",
    "\n",
    "for section in valid_sections:\n",
    "    dtype = cparser[section]['dtype']\n",
    "\n",
    "    if 'linspace' in dtype:\n",
    "        try:\n",
    "            start, end, number_bins = eval(dtype.replace('linspace', ''))\n",
    "            start = float(start)\n",
    "            end = float(end)\n",
    "            number_bins = int(number_bins)\n",
    "\n",
    "            bins = np.linspace(start, end, number_bins)\n",
    "\n",
    "            # transform section of df with the help of bins!\n",
    "            df[section] = df[section].map(lambda x: np.digitize(x, bins))\n",
    "\n",
    "        except:\n",
    "            print(f\"dtype of section {section} was parsed as {dtype}, but we encountered an error.\")\n",
    "            raise\n",
    "            \n",
    "    elif 'date_range' in dtype:\n",
    "        \n",
    "        try:\n",
    "            # parse start date, end date, bins\n",
    "            start, end, periods = eval(dtype.replace('date_range', ''))\n",
    "            start = pd.Timestamp(start)\n",
    "            end = pd.Timestamp(end)\n",
    "            periods = int(periods)\n",
    "            \n",
    "            bins = np.linspace(start, end, periods)\n",
    "            \n",
    "            df[section] = df[section].map(lambda x: np.digitize(x, bins))\n",
    "            \n",
    "        except:\n",
    "            print(f\"dtype of section {section} was parsed as {dtype}, but we encountered an error.\")\n",
    "            raise\n",
    "    elif dtype == 'str':\n",
    "        df[section] = df[section].map(lambda x: x.lower().strip().replace(' ', '_'))\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    # construct label encoder, fit label encoder, transform column\n",
    "    tmp_encoder = LabelEncoder()\n",
    "    tmp_encoder.fit(df[section])\n",
    "    df[section] = tmp_encoder.transform(df[section])\n",
    "    \n",
    "    # save label encoder\n",
    "    label_encoders[section] = tmp_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918a0f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.linspace(0, 10, 3)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1bb22",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    print(heythere)\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a08212b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
