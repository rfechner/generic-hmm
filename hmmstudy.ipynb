{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hidden Markov Model Study\n",
    "\n",
    "Goal: Revisit Hidden Markov Models from the start, write slow but readable code. Build a Hidden Markov Model from scratch.\n",
    "\n",
    "Stretch goals: \n",
    "- revisit Theoretic foundations for Multivariate Categorically distributed emissions.\n",
    "- how does the independence assumptions for multivariate emissions change the theory?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## In the Defense of Simple Models\n",
    "\n",
    "Motivating Hidden Markov Models is hard without asking some fundamental questions about statistical and probabilistic inference and learning.\n",
    "\n",
    "Why do we model things? What are we interested about finding out - the underlying dynamics or solely predictions into the future? Do we even want to predict into the future or are we satisfied with estimating some underlying state responsible for our observations?\n",
    "Why not choose Timeseries model type X over type Y? Well, there is no easy answer to this, it may just be that another type of model is better fit for a specific requirement.\n",
    "\n",
    "Markov Models and *Hidden* Markov Models are so-called **generative** models. This means that after building them through a process called *training* or *fitting*, we may produce new pseudo-data from our model. We may extrapolate from timepoint $t$ onwards or simulate a new trajectory. We may choose different initial conditions and see, how the model evolves. It is here, i want to make an argument for Hidden Markov Models in the age of Neural Networks. \n",
    "The biggest advantage of HMMs over Neural Methods is in my understanding, that they are **interpretable**. They are white-box models, allowing the observer to clearly understand **why** the model has produced any output. To some degree, the data **is** the model. All important information has been distilled and transformed into a model.\n",
    "\n",
    "Another big advantage is that they are **simple** models. No-hyperparamter-tuning. No tinkering with the learning rate or swapping out optimizers, adding dropout, adding layer norms, removing layer norms... The process of fitting the model is more sane. In some sense this is a half-truth, as we do have to make assumptions when we choose a model type, however they are very different types of assumptions. They encourage us to think harder about the problem and the setup, not decide on model changes depending on whether or not the $F_1$-Score is moving up or down."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions.\n",
    "\n",
    "Let a Hidden Markov Model be a tuple $\\lambda = (\\mathcal A, \\mathcal B, \\pi)$ where \n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal A := p(x_{t}|X_{0:t-1})\\quad & \\text{Conditional distribution over hidden state given previous hidden states}\\\\\n",
    "    \\mathcal B := p(y_{t}|X_{0:t})\\quad& \\text{Conditional distribution over emission signal given current and previous hidden states}\\\\ \n",
    "    \\pi := p(x_0)\\quad & \\text{Initial state distribution}\n",
    "\\end{align*}\n",
    "\n",
    "In my thesis and the following study, we will look at a special case of HMMs, where $\\mathcal A, \\mathcal B$ and $\\pi$ are categorical distributions, making them row-stochastic matrices containing transition and emission probabilities. The probabilistic formulation of the object lets us see however, how we might use **Bayes-Rule** to do inference on the hidden states, as\n",
    "\n",
    "$$\n",
    "    p(X_{0:t}|y_t) = \\frac{p(y_t|X_{0:t})p(X_{0:t})}{p(y_t)} \\quad \\text{ or } \\quad p(X_{0:N}| Y_{0:N}) = \\frac{p(Y_{0:N}|X_{0:N})p(X_{0:N})}{p(Y_{0:N})}\n",
    "$$\n",
    "\n",
    "Calculating these expressions however is untractable, as it would require us to compute large integrals $p(Y) = \\int p(Y|X)p(X) dX$ where $p(X) = p(x_0)p(x_1|x_0)\\dots p(x_N|x_0, \\dots, x_{N-1})$ itself would be tricky to compute. It is here where we make **simplifying independence assumptions** called the *Markov Assumption*:\n",
    "\n",
    "$$\n",
    "    p(x_t|x_0, x_1, \\dots x_{t-1}) = p(x_t|x_{t-1}) \\quad \\text{and} \\quad p(y_t|x_0, x_1, \\dots, x_{t}) = p(y_t|x_t)\n",
    "$$\n",
    "\n",
    "In words, we assume that transitions only depend on the previously visited state and that emissions only depend on the current hidden state. This simplifies the computations, as we may factor expressions as $p(X)$ into parts. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductory Example\n",
    "\n",
    "We are concerned with making statements about any **hidden** or **latent** variable $x$. In this example, lets consider the following setup: You're sitting at home, listening to the weather news on the radio. The true weather however is not-observable, as your window blinds are down. In our model, the true weather will be the non-observable (i.e. the *hidden* variable $x_t$) and the news will be the observable variable $y_t$. There are only two different 'true' weather states: Sunny $S$ and Rainy $R$, whereas the media reports three different observations: Dry $D$, Wet $W$ and Cloudy $C$.\n",
    "The prior over the hidden states is a discrete uniform distribution. Additionally, we **know** $\\mathcal A, \\mathcal B$. \n",
    "\n",
    "**IMPORTANT** This is obviously a shortcut. In reality we dont know $\\mathcal A$ and $\\mathcal B$, we have to fit them, using our data! Notice, how our motivation has changed the model and how we use it. Instead of being interested *how exactly* the weather changes or in which hidden state what wheather observation is made, we focus on prediction rather than trying to understand underlying dynamics.\n",
    "\n",
    "We summarize the assumptions with these equations:\n",
    "\n",
    "\\begin{align*}\n",
    "    \\mathcal A &= \\begin{bmatrix}\n",
    "        P(S|S) & P(R|S)\\\\\n",
    "        P(S|R) & P(R|R)\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "        0.7 & 0.3\\\\\n",
    "        0.2 & 0.8\n",
    "    \\end{bmatrix}\\\\\n",
    "    \\mathcal B &= \\begin{bmatrix}\n",
    "        P(D|S) & P(W|S) & P(C|S)\\\\\n",
    "        P(D|R) & P(W|R) & P(C|R)\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "        0.5 & 0.3 & 0.2\\\\\n",
    "        0.0 & 0.8 & 0.2\n",
    "    \\end{bmatrix}\\\\\n",
    "    \\pi &= \\begin{bmatrix}\n",
    "        P(x_0 = S)\\\\\n",
    "        P(x_0 = R)\n",
    "    \\end{bmatrix} = \\begin{bmatrix}\n",
    "        0.5\\\\\n",
    "        0.5\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting and Updating\n",
    "\n",
    "Inference on timeseries is usually separated into three steps: **predicting** the next hidden state $\\tilde x = p(x_t| X_{0:t-1}, Y_{0:t-1})$ and **updating** said prediction once we have observed the current emission $\\hat x = p(x_t | X_{0:t-1}, Y_{0:t-1}, y_t)$\n",
    "\n",
    "The recursive prediction equation is:\n",
    "\n",
    "$$\n",
    "    p(x_t| Y_{0:t-1}) = \\int \\underbrace{p(x_t|x_{t-1})}_{\\text{hidden state dynamics}}\\cdot \\overbrace{p(x_{t-1}|Y_{0:t-1})}^{\\text{previous update result} } dx_{t-1}  \n",
    "$$\n",
    "\n",
    "This is a local integral over $x_{t-1}$, which we may be able to solve, if we have access to the previous update result, which is similarily recursively defined as:\n",
    "\n",
    "$$\n",
    "    p(x_t|Y_{0:t}) = \\frac{\\overbrace{p(y_t|x_t)}^{\\text{likelihood}}\\overbrace{p(x_t|Y_{0:t-1})}^{\\quad \\text{prev. prediction result}}}{\\int p(y_t | x_t )p(x_t | Y_{0:tâˆ’1}) dx_t}\n",
    "$$\n",
    "\n",
    "We can see, that we have to compute the prediction and the update recursively, in order to get an updated estimate of the distribution over $x_t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculation\n",
    "\n",
    "Now, how would we go about calculating these quantities? We should start at the beginning, calculating the prediction of $x_1$, before updating it with our observation. For the sake of this eaxmple, lets assume we've observed the sequence $Y_{0:3} = \\{ D, C, C, W\\}$ and the state and emission matrices are as described above.\n",
    "\n",
    "Calculate the update for $t=0$:\n",
    "\n",
    "\\begin{align*}\n",
    "    p(x_0) &= \\pi\\\\\n",
    "    p(x_0|y_0) &= \\frac{p(y_0|x_0)p(x_0)}{\\int p(y_0|x_0)p(x_0) dx_0} = \\frac{\\begin{bmatrix}\n",
    "        P(D|S)\\\\\n",
    "        P(D|R)\n",
    "    \\end{bmatrix}\\odot \\begin{bmatrix}\n",
    "        P(S)\\\\\n",
    "        P(R)\n",
    "    \\end{bmatrix}}{P(D|S)P(S) + P(D|R)P(R)}\\\\\n",
    "    &= \\frac{\\begin{bmatrix}\n",
    "        0.5\\\\\n",
    "        0.0\n",
    "    \\end{bmatrix}\\odot \\begin{bmatrix}\n",
    "        0.5\\\\\n",
    "        0.5\n",
    "    \\end{bmatrix}}{0.5 \\cdot 0.5 + 0.0 \\cdot 0.5} = \\begin{bmatrix}\n",
    "        1\\\\\n",
    "        0\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Seems like after seeing the first observation $y_0 = D$, we are completely convinced, that it is sunny outside. Lets see, what happens, if we predict the next hidden state.\n",
    "\n",
    "\\begin{align*}\n",
    "    p(x_0|y_0) &= \\begin{bmatrix}\n",
    "        1\\\\\n",
    "        0\n",
    "    \\end{bmatrix}\\\\\n",
    "    p(x_1|x_0, y_0) &= \\int p(x_1|x_0)p(x_0|y_0)dx_0\\\\\n",
    "    &= \\mathcal A ^T p(x_0|y_0)\\\\\n",
    "    &= \\begin{bmatrix}\n",
    "        0.7\\\\\n",
    "        0.3\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets update for our estimate of the hidden state at $t=1$. For this, we calculate the update analogously to our update at timestep $t= 0$, with the difference, that now we use the posterior of the prediction as the prior.\n",
    "\n",
    "\\begin{align*}\n",
    "    p(x_1) &= p(x_1|y_0, x_0) = \\begin{bmatrix}\n",
    "    0.7\\\\\n",
    "    0.3\n",
    "    \\end{bmatrix}\\\\\n",
    "    p(x_1|Y_{0:1}) &= \\frac{\\mathcal B[:, 2] \\odot p(x_1|y_0, x_0)}{\\sum_i \\mathcal B[:, 2] \\odot p(x_1|y_0, x_0)}\\\\\n",
    "    &= \\frac{\\begin{bmatrix}\n",
    "        0.2\\\\\n",
    "        0.2\n",
    "    \\end{bmatrix}\\odot \\begin{bmatrix}\n",
    "        0.7\\\\\n",
    "        0.3\n",
    "    \\end{bmatrix}}{0.2 \\cdot 0.7 + 0.2 \\cdot 0.3}\\\\\n",
    "    &= \\begin{bmatrix}\n",
    "        0.7\\\\\n",
    "        0.3\n",
    "    \\end{bmatrix}\n",
    "\\end{align*}\\\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "We will put this prediction and update routine in code below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "A = np.array([\n",
    "    [0.7, 0.3],\n",
    "    [0.2, 0.8]\n",
    "])\n",
    "\n",
    "B = np.array([\n",
    "    [0.5, 0.2, 0.3],\n",
    "    [0.0, 0.2, 0.8]\n",
    "])\n",
    "\n",
    "x_0 = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x_tm1 : np.ndarray, y_t : int,  B : np.ndarray) -> np.ndarray:\n",
    "\n",
    "    likelihood = B[:, y_t]\n",
    "    prior = x_tm1\n",
    "\n",
    "    posterior_unnormalized = likelihood * prior\n",
    "    return posterior_unnormalized / posterior_unnormalized.sum()\n",
    "\n",
    "def predict(x_tm1 : np.ndarray, A : np.ndarray) -> np.ndarray:\n",
    "\n",
    "    # check for row-stochasticity\n",
    "    assert np.all(np.isclose(A.sum(axis=1), 1)), \"Matrix A doesn't seem to be row-stochastic\"\n",
    "\n",
    "    #check if x_tm1 is a valid probability distribution\n",
    "    assert np.isclose(x_tm1.sum(), 1), \"x_tm1 isn't stochastic, sum != 1\"\n",
    "\n",
    "    return A.T @ np.atleast_1d(x_tm1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.5, 0.5]),\n",
       "  array([0.7, 0.3]),\n",
       "  array([0.55, 0.45]),\n",
       "  array([0.475, 0.525]),\n",
       "  array([0.32666667, 0.67333333])],\n",
       " [array([1., 0.]),\n",
       "  array([0.7, 0.3]),\n",
       "  array([0.55, 0.45]),\n",
       "  array([0.25333333, 0.74666667])])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = [0, 1, 1, 2] # [D, C, C, W]\n",
    "x_tm1 = x_0\n",
    "predictions = [x_0]\n",
    "updates = []\n",
    "\n",
    "for y_i in observations:\n",
    "    x_updated = update(x_tm1, y_i, B)\n",
    "    x_tm1 = predict(x_updated, A)\n",
    "\n",
    "    updates.append(x_updated)\n",
    "    predictions.append(x_tm1)\n",
    "\n",
    "    \n",
    "predictions, updates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Case\n",
    "\n",
    "Before looking at smoothing, let us think about changing the likelihood function $p(y_t | x_t)$. What would change, if y_t would be a collection of $K$ independent categorically distributed random variables instead of a single random variable? We would have to keep track of $K$ different emission matrices and calculate the update differently, as $p(y_t|x_t)$ now expands into $\\prod_{i = 1}^K p(y^i_t | x_t)$.\n",
    "\n",
    "We extend our example of the TV and weather with another observation variable. Lets assume we would observe dogs barking depending on the weather. If it's sunny, people much rather go out to walk their dog than if its raining. From this assumption follows the emission matrix $\\mathcal B_2 = \\begin{bmatrix}\n",
    "    P(B|S) & P(\\neg B|S)\\\\\n",
    "    P(B|R) & P(\\neg B|R)\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "    0.6 & 0.4\\\\\n",
    "    0.1 & 0.9\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = np.array([\n",
    "    [0.7, 0.3],\n",
    "    [0.2, 0.8]\n",
    "])\n",
    "\n",
    "B_1 = np.array([\n",
    "    [0.5, 0.2, 0.3],\n",
    "    [0.0, 0.2, 0.8]\n",
    "])\n",
    "\n",
    "B_2 = np.array([\n",
    "    [0.6, 0.4],\n",
    "    [0.1, 0.9]\n",
    "])\n",
    "\n",
    "x_0 = np.array([0.5, 0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(x_tm1 : np.ndarray, y_t : Sequence[int],  Bs : Sequence[np.ndarray]) -> np.ndarray:\n",
    "\n",
    "    \"\"\"\n",
    "        x_tm1   : np.ndarray        vector of hidden state distribution from timestep t-1\n",
    "        y_t     : Sequence[int]     Sequence of ints, int at index i contains observation for corresponding emission matrix at index i\n",
    "        Bs      : Sequence[np.ndarray]  Sequence of emission matrices              \n",
    "    \"\"\"\n",
    "\n",
    "    # likelihood p(y_t | x_t) factorizes into p(y^1_t|x_t) * p(y^2_t|x_t) * ... *  p(y^K_t|x_t)\n",
    "    likelihoods = np.ones_like(x_tm1)\n",
    "    for y, B in zip(y_t, Bs):\n",
    "        likelihoods *= B[:, y]\n",
    "    prior = x_tm1\n",
    "    \n",
    "    posterior_unnormalized = likelihoods * prior\n",
    "    return posterior_unnormalized / posterior_unnormalized.sum()\n",
    "\n",
    "def predict(x_tm1 : np.ndarray, A : np.ndarray) -> np.ndarray:\n",
    "\n",
    "    # check for row-stochasticity\n",
    "    assert np.all(np.isclose(A.sum(axis=1), 1)), \"Matrix A doesn't seem to be row-stochastic\"\n",
    "\n",
    "    #check if x_tm1 is a valid probability distribution\n",
    "    assert np.isclose(x_tm1.sum(), 1), \"x_tm1 isn't stochastic, sum != 1\"\n",
    "\n",
    "    return A.T @ np.atleast_1d(x_tm1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([array([0.5, 0.5]),\n",
       "  array([0.7, 0.3]),\n",
       "  array([0.66666667, 0.33333333]),\n",
       "  array([0.43529412, 0.56470588]),\n",
       "  array([0.61111111, 0.38888889])],\n",
       " [array([1., 0.]),\n",
       "  array([0.93333333, 0.06666667]),\n",
       "  array([0.47058824, 0.52941176]),\n",
       "  array([0.82222222, 0.17777778])])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "observations = [[0, 1], [1, 0], [1, 1], [1, 0]] # (D, not B), (C, B), (C, not B), (W, B)\n",
    "B = [B_1, B_2]\n",
    "x_tm1 = x_0\n",
    "predictions = [x_0]\n",
    "updates = []\n",
    "\n",
    "for y_i in observations:\n",
    "    x_updated = update(x_tm1, y_i, B)\n",
    "    x_tm1 = predict(x_updated, A)\n",
    "\n",
    "    updates.append(x_updated)\n",
    "    predictions.append(x_tm1)\n",
    "\n",
    "    \n",
    "predictions, updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generic-hmm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
